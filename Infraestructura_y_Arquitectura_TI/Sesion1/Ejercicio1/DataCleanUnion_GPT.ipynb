{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y Unión de Datos (Manejo de errores mejorado)\n",
    "\n",
    "Este cuaderno realiza la limpieza y unión de datos de tres archivos diferentes: data.txt, data1.txt y data3.txt, con manejo robusto de errores y inconsistencias en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Importar las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Definir funciones auxiliares (actualizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_carpetas():\n",
    "    for carpeta in ['input', 'output']:\n",
    "        if not os.path.exists(carpeta):\n",
    "            os.makedirs(carpeta)\n",
    "            print(f\"Carpeta '{carpeta}' creada.\")\n",
    "\n",
    "def leer_archivo_con_errores(filename):\n",
    "    filepath = os.path.join('input', filename)\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    header = lines[0].strip().split(',')\n",
    "    data = []\n",
    "    for i, line in enumerate(lines[1:], start=2):\n",
    "        fields = line.strip().split(',')\n",
    "        if len(fields) != len(header):\n",
    "            print(f\"Advertencia: La línea {i} en {filename} tiene {len(fields)} campos en lugar de {len(header)}.\")\n",
    "            print(f\"Contenido de la línea: {line.strip()}\")\n",
    "            fields = fields[:len(header)]  # Truncar si hay más campos de lo esperado\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=header)\n",
    "    return df\n",
    "\n",
    "def limpiar_dataframe(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].str.strip().replace('', np.nan)\n",
    "    \n",
    "    for col in ['age', 'height', 'weight', 'salary']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    if 'city' in df.columns:\n",
    "        df['city'] = df['city'].apply(lambda x: 'Houston' if isinstance(x, str) and fuzz.ratio(x, 'Houston') > 80 else x)\n",
    "        df['city'] = df['city'].apply(lambda x: 'Miami' if isinstance(x, str) and fuzz.ratio(x, 'Miami') > 80 else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def unificar_unidades(df):\n",
    "    if 'height' in df.columns and df['height'].median() < 100:\n",
    "        df['height'] = df['height'] * 2.54\n",
    "    \n",
    "    if 'weight' in df.columns and df['weight'].median() > 100:\n",
    "        df['weight'] = df['weight'] * 0.453592\n",
    "    \n",
    "    return df\n",
    "\n",
    "def eliminar_outliers(df):\n",
    "    for col in ['age', 'height', 'weight', 'salary']:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Crear carpetas de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_carpetas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Leer y limpiar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertencia: La línea 7 en data1.txt tiene 7 campos en lugar de 6.\n",
      "Contenido de la línea: \"Frank\", 35, 69.0, 154.3, 58000, \"Washington, D.C.\"\n",
      "Advertencia: La línea 7 en data.txt tiene 7 campos en lugar de 6.\n",
      "Contenido de la línea: \"Frank\", 35, 175.5, 70.0, , \"Washington, D.C.\"\n",
      "Advertencia: La línea 13 en data.txt tiene 8 campos en lugar de 6.\n",
      "Contenido de la línea: \"Liam\", 24, 178.5, 73.5, 61000, , ,\n",
      "Advertencia: La línea 18 en data.txt tiene 8 campos en lugar de 6.\n",
      "Contenido de la línea: \"Quinn\", , 172.0, 77.5, 57000, , ,\n",
      "Advertencia: La línea 21 en data.txt tiene 1 campos en lugar de 6.\n",
      "Contenido de la línea: \n",
      "Columnas en df1: ['\"name\"', 'age', '\"height_(inches)\"', '\"weight_(pounds)\"', '\"salary_($)\"', '\"city\"']\n",
      "Columnas en df2: ['\"name\"', 'sex', '\"marital_status\"', 'career']\n",
      "Columnas en df3: ['name', 'age', 'height_(cm)', 'weight_(kg)', 'salary_($)', 'city']\n",
      "\n",
      "Primeras filas de df1:\n",
      "      \"name\"  age \"height_(inches)\" \"weight_(pounds)\" \"salary_($)\"  \\\n",
      "0      \"Amy\"   30              65.5             132.3        50000   \n",
      "1      \"Ben\"   25              68.0             165.3        60000   \n",
      "2  \"Charlie\"   32              67.0             180.5        55000   \n",
      "3    \"David\"   26              70.0             188.7        59000   \n",
      "4     \"Ella\"   28              61.0             126.0        52000   \n",
      "\n",
      "            \"city\"  \n",
      "0       \"New York\"  \n",
      "1    \"Los Angeles\"  \n",
      "2        \"Chicago\"  \n",
      "3  \"San Francisco\"  \n",
      "4        \"Bristol\"  \n",
      "\n",
      "Primeras filas de df2:\n",
      "      \"name\"     sex \"marital_status\"             career\n",
      "0    \"Alice\"  Female           Single     Data Scientist\n",
      "1      \"Bob\"    Male           Single  Software Engineer\n",
      "2  \"Charlie\"    Male          Married             Doctor\n",
      "3    \"David\"    Male           Single             Lawyer\n",
      "4      \"Eve\"  Female         Divorced             Artist\n",
      "\n",
      "Primeras filas de df3:\n",
      "        name   age height_(cm) weight_(kg) salary_($)             city\n",
      "0    \"Alice\"  30.0       165.5        60.2      50000       \"New York\"\n",
      "1      \"Bob\"  25.0       175.0        75.0      60000    \"Los Angeles\"\n",
      "2  \"Charlie\"  32.0       170.5         NaN      55000        \"Chicago\"\n",
      "3    \"David\"  26.0       180.0        85.5      59000  \"San Francisco\"\n",
      "4      \"Eve\"   NaN         160          58      52000       \" Bristol\"\n"
     ]
    }
   ],
   "source": [
    "df1 = leer_archivo_con_errores('data1.txt')\n",
    "df2 = leer_archivo_con_errores('data3.txt')\n",
    "df3 = leer_archivo_con_errores('data.txt')\n",
    "\n",
    "df1 = limpiar_dataframe(df1)\n",
    "df2 = limpiar_dataframe(df2)\n",
    "df3 = limpiar_dataframe(df3)\n",
    "\n",
    "print(\"Columnas en df1:\", df1.columns.tolist())\n",
    "print(\"Columnas en df2:\", df2.columns.tolist())\n",
    "print(\"Columnas en df3:\", df3.columns.tolist())\n",
    "\n",
    "print(\"\\nPrimeras filas de df1:\")\n",
    "print(df1.head())\n",
    "print(\"\\nPrimeras filas de df2:\")\n",
    "print(df2.head())\n",
    "print(\"\\nPrimeras filas de df3:\")\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Unificar unidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de df1 después de unificar unidades:\n",
      "             age\n",
      "count  10.000000\n",
      "mean   29.400000\n",
      "std     3.339993\n",
      "min    25.000000\n",
      "25%    27.250000\n",
      "50%    28.500000\n",
      "75%    31.500000\n",
      "max    35.000000\n",
      "\n",
      "Estadísticas de df2 después de unificar unidades:\n",
      "         \"name\"   sex \"marital_status\" career\n",
      "count        29    29               29     29\n",
      "unique       24     3                3     21\n",
      "top     \"David\"  Male           Single  Nurse\n",
      "freq          2    15               16      3\n",
      "\n",
      "Estadísticas de df3 después de unificar unidades:\n",
      "             age\n",
      "count  16.000000\n",
      "mean   29.375000\n",
      "std     3.442383\n",
      "min    24.000000\n",
      "25%    26.750000\n",
      "50%    29.500000\n",
      "75%    32.250000\n",
      "max    35.000000\n"
     ]
    }
   ],
   "source": [
    "df1 = unificar_unidades(df1)\n",
    "df2 = unificar_unidades(df2)\n",
    "df3 = unificar_unidades(df3)\n",
    "\n",
    "print(\"Estadísticas de df1 después de unificar unidades:\")\n",
    "print(df1.describe())\n",
    "print(\"\\nEstadísticas de df2 después de unificar unidades:\")\n",
    "print(df2.describe())\n",
    "print(\"\\nEstadísticas de df3 después de unificar unidades:\")\n",
    "print(df3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Combinar los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame combinado: (59, 14)\n",
      "\n",
      "Columnas en el DataFrame combinado: ['\"name\"', 'age', '\"height_(inches)\"', '\"weight_(pounds)\"', '\"salary_($)\"', '\"city\"', 'sex', '\"marital_status\"', 'career', 'name', 'height_(cm)', 'weight_(kg)', 'salary_($)', 'city']\n",
      "\n",
      "Primeras filas del DataFrame combinado:\n",
      "      \"name\"   age \"height_(inches)\" \"weight_(pounds)\" \"salary_($)\"  \\\n",
      "0      \"Amy\"  30.0              65.5             132.3        50000   \n",
      "1      \"Ben\"  25.0              68.0             165.3        60000   \n",
      "2  \"Charlie\"  32.0              67.0             180.5        55000   \n",
      "3    \"David\"  26.0              70.0             188.7        59000   \n",
      "4     \"Ella\"  28.0              61.0             126.0        52000   \n",
      "\n",
      "            \"city\"  sex \"marital_status\" career name height_(cm) weight_(kg)  \\\n",
      "0       \"New York\"  NaN              NaN    NaN  NaN         NaN         NaN   \n",
      "1    \"Los Angeles\"  NaN              NaN    NaN  NaN         NaN         NaN   \n",
      "2        \"Chicago\"  NaN              NaN    NaN  NaN         NaN         NaN   \n",
      "3  \"San Francisco\"  NaN              NaN    NaN  NaN         NaN         NaN   \n",
      "4        \"Bristol\"  NaN              NaN    NaN  NaN         NaN         NaN   \n",
      "\n",
      "  salary_($) city  \n",
      "0        NaN  NaN  \n",
      "1        NaN  NaN  \n",
      "2        NaN  NaN  \n",
      "3        NaN  NaN  \n",
      "4        NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print(\"Forma del DataFrame combinado:\", df_combined.shape)\n",
    "print(\"\\nColumnas en el DataFrame combinado:\", df_combined.columns.tolist())\n",
    "print(\"\\nPrimeras filas del DataFrame combinado:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame después de eliminar duplicados: (20, 14)\n"
     ]
    }
   ],
   "source": [
    "df_combined = df_combined.drop_duplicates(subset='name', keep='first')\n",
    "print(\"Forma del DataFrame después de eliminar duplicados:\", df_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Eliminar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame después de eliminar outliers: (17, 14)\n",
      "\n",
      "Estadísticas del DataFrame final:\n",
      "             age\n",
      "count  17.000000\n",
      "mean   29.411765\n",
      "std     3.336518\n",
      "min    24.000000\n",
      "25%    27.000000\n",
      "50%    30.000000\n",
      "75%    32.000000\n",
      "max    35.000000\n"
     ]
    }
   ],
   "source": [
    "df_combined = eliminar_outliers(df_combined)\n",
    "print(\"Forma del DataFrame después de eliminar outliers:\", df_combined.shape)\n",
    "print(\"\\nEstadísticas del DataFrame final:\")\n",
    "print(df_combined.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Guardar en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en output\\datos_combinados_limpios.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join('output', 'datos_combinados_limpios.xlsx')\n",
    "df_combined.to_excel(output_path, index=False)\n",
    "print(f\"Datos guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
