{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y Unión de Datos (Manejo de columnas duplicadas)\n",
    "\n",
    "Este cuaderno realiza la limpieza y unión de datos de tres archivos diferentes: data.txt, data1.txt y data3.txt, con manejo robusto de errores, inconsistencias en los datos y eliminación de columnas duplicadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Importar las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Definir funciones auxiliares (actualizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_carpetas():\n",
    "    for carpeta in ['input', 'output']:\n",
    "        if not os.path.exists(carpeta):\n",
    "            os.makedirs(carpeta)\n",
    "            print(f\"Carpeta '{carpeta}' creada.\")\n",
    "\n",
    "def leer_archivo_con_errores(filename):\n",
    "    filepath = os.path.join('input', filename)\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    header = [col.strip().lower().replace(' ', '_') for col in lines[0].strip().split(',')]\n",
    "    data = []\n",
    "    for i, line in enumerate(lines[1:], start=2):\n",
    "        fields = [field.strip() for field in line.strip().split(',')]\n",
    "        if len(fields) != len(header):\n",
    "            print(f\"Advertencia: La línea {i} en {filename} tiene {len(fields)} campos en lugar de {len(header)}.\")\n",
    "            print(f\"Contenido de la línea: {line.strip()}\")\n",
    "            fields = fields[:len(header)]  # Truncar si hay más campos de lo esperado\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=header)\n",
    "    return df\n",
    "\n",
    "def limpiar_dataframe(df):\n",
    "    # Eliminar columnas duplicadas\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    \n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].str.strip().replace('', np.nan)\n",
    "    \n",
    "    for col in ['age', 'height', 'weight', 'salary']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    if 'city' in df.columns:\n",
    "        df['city'] = df['city'].apply(lambda x: 'Houston' if isinstance(x, str) and fuzz.ratio(x, 'Houston') > 80 else x)\n",
    "        df['city'] = df['city'].apply(lambda x: 'Miami' if isinstance(x, str) and fuzz.ratio(x, 'Miami') > 80 else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def unificar_unidades(df):\n",
    "    if 'height' in df.columns and df['height'].median() < 100:\n",
    "        df['height'] = df['height'] * 2.54\n",
    "    \n",
    "    if 'weight' in df.columns and df['weight'].median() > 100:\n",
    "        df['weight'] = df['weight'] * 0.453592\n",
    "    \n",
    "    return df\n",
    "\n",
    "def eliminar_outliers(df):\n",
    "    for col in ['age', 'height', 'weight', 'salary']:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "def eliminar_columnas_duplicadas(df):\n",
    "    # Crear un diccionario para almacenar columnas únicas\n",
    "    columnas_unicas = {}\n",
    "    for columna in df.columns:\n",
    "        nombre_limpio = columna.strip().lower().replace(' ', '_').replace('\"', '')\n",
    "        if nombre_limpio not in columnas_unicas:\n",
    "            columnas_unicas[nombre_limpio] = columna\n",
    "    \n",
    "    # Crear un nuevo DataFrame con las columnas únicas\n",
    "    df_limpio = df[list(columnas_unicas.values())].copy()\n",
    "    \n",
    "    # Renombrar las columnas al formato limpio\n",
    "    df_limpio.columns = list(columnas_unicas.keys())\n",
    "    \n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Crear carpetas de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_carpetas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Leer y limpiar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertencia: La línea 7 en data1.txt tiene 7 campos en lugar de 6.\n",
      "Contenido de la línea: \"Frank\", 35, 69.0, 154.3, 58000, \"Washington, D.C.\"\n",
      "Advertencia: La línea 7 en data.txt tiene 7 campos en lugar de 6.\n",
      "Contenido de la línea: \"Frank\", 35, 175.5, 70.0, , \"Washington, D.C.\"\n",
      "Advertencia: La línea 13 en data.txt tiene 8 campos en lugar de 6.\n",
      "Contenido de la línea: \"Liam\", 24, 178.5, 73.5, 61000, , ,\n",
      "Advertencia: La línea 18 en data.txt tiene 8 campos en lugar de 6.\n",
      "Contenido de la línea: \"Quinn\", , 172.0, 77.5, 57000, , ,\n",
      "Advertencia: La línea 21 en data.txt tiene 1 campos en lugar de 6.\n",
      "Contenido de la línea: \n",
      "Columnas en df1: ['\"name\"', 'age', '\"height_(inches)\"', '\"weight_(pounds)\"', '\"salary_($)\"', '\"city\"']\n",
      "Columnas en df2: ['\"name\"', 'sex', '\"marital_status\"', 'career']\n",
      "Columnas en df3: ['name', 'age', 'height_(cm)', 'weight_(kg)', 'salary_($)', 'city']\n",
      "\n",
      "Primeras filas de df1:\n",
      "      \"name\"  age \"height_(inches)\" \"weight_(pounds)\" \"salary_($)\"  \\\n",
      "0      \"Amy\"   30              65.5             132.3        50000   \n",
      "1      \"Ben\"   25              68.0             165.3        60000   \n",
      "2  \"Charlie\"   32              67.0             180.5        55000   \n",
      "3    \"David\"   26              70.0             188.7        59000   \n",
      "4     \"Ella\"   28              61.0             126.0        52000   \n",
      "\n",
      "            \"city\"  \n",
      "0       \"New York\"  \n",
      "1    \"Los Angeles\"  \n",
      "2        \"Chicago\"  \n",
      "3  \"San Francisco\"  \n",
      "4        \"Bristol\"  \n",
      "\n",
      "Primeras filas de df2:\n",
      "      \"name\"     sex \"marital_status\"             career\n",
      "0    \"Alice\"  Female           Single     Data Scientist\n",
      "1      \"Bob\"    Male           Single  Software Engineer\n",
      "2  \"Charlie\"    Male          Married             Doctor\n",
      "3    \"David\"    Male           Single             Lawyer\n",
      "4      \"Eve\"  Female         Divorced             Artist\n",
      "\n",
      "Primeras filas de df3:\n",
      "        name   age height_(cm) weight_(kg) salary_($)             city\n",
      "0    \"Alice\"  30.0       165.5        60.2      50000       \"New York\"\n",
      "1      \"Bob\"  25.0       175.0        75.0      60000    \"Los Angeles\"\n",
      "2  \"Charlie\"  32.0       170.5         NaN      55000        \"Chicago\"\n",
      "3    \"David\"  26.0       180.0        85.5      59000  \"San Francisco\"\n",
      "4      \"Eve\"   NaN         160          58      52000       \" Bristol\"\n"
     ]
    }
   ],
   "source": [
    "df1 = leer_archivo_con_errores('data1.txt')\n",
    "df2 = leer_archivo_con_errores('data3.txt')\n",
    "df3 = leer_archivo_con_errores('data.txt')\n",
    "\n",
    "df1 = limpiar_dataframe(df1)\n",
    "df2 = limpiar_dataframe(df2)\n",
    "df3 = limpiar_dataframe(df3)\n",
    "\n",
    "print(\"Columnas en df1:\", df1.columns.tolist())\n",
    "print(\"Columnas en df2:\", df2.columns.tolist())\n",
    "print(\"Columnas en df3:\", df3.columns.tolist())\n",
    "\n",
    "print(\"\\nPrimeras filas de df1:\")\n",
    "print(df1.head())\n",
    "print(\"\\nPrimeras filas de df2:\")\n",
    "print(df2.head())\n",
    "print(\"\\nPrimeras filas de df3:\")\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Unificar unidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de df1 después de unificar unidades:\n",
      "             age\n",
      "count  10.000000\n",
      "mean   29.400000\n",
      "std     3.339993\n",
      "min    25.000000\n",
      "25%    27.250000\n",
      "50%    28.500000\n",
      "75%    31.500000\n",
      "max    35.000000\n",
      "\n",
      "Estadísticas de df2 después de unificar unidades:\n",
      "         \"name\"   sex \"marital_status\" career\n",
      "count        29    29               29     29\n",
      "unique       24     3                3     21\n",
      "top     \"David\"  Male           Single  Nurse\n",
      "freq          2    15               16      3\n",
      "\n",
      "Estadísticas de df3 después de unificar unidades:\n",
      "             age\n",
      "count  16.000000\n",
      "mean   29.375000\n",
      "std     3.442383\n",
      "min    24.000000\n",
      "25%    26.750000\n",
      "50%    29.500000\n",
      "75%    32.250000\n",
      "max    35.000000\n"
     ]
    }
   ],
   "source": [
    "df1 = unificar_unidades(df1)\n",
    "df2 = unificar_unidades(df2)\n",
    "df3 = unificar_unidades(df3)\n",
    "\n",
    "print(\"Estadísticas de df1 después de unificar unidades:\")\n",
    "print(df1.describe())\n",
    "print(\"\\nEstadísticas de df2 después de unificar unidades:\")\n",
    "print(df2.describe())\n",
    "print(\"\\nEstadísticas de df3 después de unificar unidades:\")\n",
    "print(df3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Combinar los DataFrames y eliminar columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame combinado: (59, 11)\n",
      "\n",
      "Columnas en el DataFrame combinado: ['name', 'age', 'height_(inches)', 'weight_(pounds)', 'salary_($)', 'city', 'sex', 'marital_status', 'career', 'height_(cm)', 'weight_(kg)']\n",
      "\n",
      "Primeras filas del DataFrame combinado:\n",
      "        name   age height_(inches) weight_(pounds) salary_($)  \\\n",
      "0      \"Amy\"  30.0            65.5           132.3      50000   \n",
      "1      \"Ben\"  25.0            68.0           165.3      60000   \n",
      "2  \"Charlie\"  32.0            67.0           180.5      55000   \n",
      "3    \"David\"  26.0            70.0           188.7      59000   \n",
      "4     \"Ella\"  28.0            61.0           126.0      52000   \n",
      "\n",
      "              city  sex marital_status career height_(cm) weight_(kg)  \n",
      "0       \"New York\"  NaN            NaN    NaN         NaN         NaN  \n",
      "1    \"Los Angeles\"  NaN            NaN    NaN         NaN         NaN  \n",
      "2        \"Chicago\"  NaN            NaN    NaN         NaN         NaN  \n",
      "3  \"San Francisco\"  NaN            NaN    NaN         NaN         NaN  \n",
      "4        \"Bristol\"  NaN            NaN    NaN         NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df_combined = eliminar_columnas_duplicadas(df_combined)\n",
    "print(\"Forma del DataFrame combinado:\", df_combined.shape)\n",
    "print(\"\\nColumnas en el DataFrame combinado:\", df_combined.columns.tolist())\n",
    "print(\"\\nPrimeras filas del DataFrame combinado:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame después de eliminar duplicados: (25, 11)\n"
     ]
    }
   ],
   "source": [
    "df_combined = df_combined.drop_duplicates(subset='name', keep='first')\n",
    "print(\"Forma del DataFrame después de eliminar duplicados:\", df_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Eliminar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame después de eliminar outliers: (11, 11)\n",
      "\n",
      "Estadísticas del DataFrame final:\n",
      "             age\n",
      "count  11.000000\n",
      "mean   29.454545\n",
      "std     3.173756\n",
      "min    25.000000\n",
      "25%    27.500000\n",
      "50%    29.000000\n",
      "75%    31.000000\n",
      "max    35.000000\n"
     ]
    }
   ],
   "source": [
    "df_combined = eliminar_outliers(df_combined)\n",
    "print(\"Forma del DataFrame después de eliminar outliers:\", df_combined.shape)\n",
    "print(\"\\nEstadísticas del DataFrame final:\")\n",
    "print(df_combined.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Guardar en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en output\\datos_combinados_limpios.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join('output', 'datos_combinados_limpios.xlsx')\n",
    "df_combined.to_excel(output_path, index=False)\n",
    "print(f\"Datos guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
